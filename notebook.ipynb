{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Add the path to stylegan2-ada-pytorch directory\n",
    "repo_path = '/Users/oliverlundin/Local Documents/github/facemorph/stylegan2-ada-pytorch'\n",
    "sys.path.append(repo_path)\n",
    "\n",
    "import projector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face1_path = 'face1.png'\n",
    "face2_path = 'face2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 3])\n",
      "torch.Size([512, 512, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "face1 = Image.open(face1_path)\n",
    "face2 = Image.open(face2_path)\n",
    "\n",
    "# Convert the PIL images to NumPy arrays\n",
    "face1_array = np.array(face1)\n",
    "face2_array = np.array(face2)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors with specified dtype\n",
    "face1_tensor = torch.tensor(face1_array, dtype=torch.float32)  # Change dtype as needed\n",
    "face2_tensor = torch.tensor(face2_array, dtype=torch.float32)\n",
    "\n",
    "# Print the shape of the tensors\n",
    "print(face1_tensor.shape)\n",
    "print(face2_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image channels: 3, Image resolution: 1024\n",
      "face1_tensor shape: torch.Size([3, 1024, 1024])\n",
      "face2_tensor shape: torch.Size([3, 1024, 1024])\n",
      "Expected shape: (3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Set device\n",
    "if(torch.backends.mps.is_available()): # True\n",
    "\tdevice = torch.device(\"mps\")\n",
    "\n",
    "# Load the generator model from the pickle file\n",
    "with open('ffhq.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)['G_ema']\n",
    "    \n",
    "\n",
    "G.to(device)\n",
    "\n",
    "print(f\"Image channels: {G.img_channels}, Image resolution: {G.img_resolution}\")\n",
    "\n",
    "face1_tensor = face1_tensor.squeeze()\n",
    "face1_tensor = face1_tensor.permute(2, 0, 1)\n",
    "face1_tensor = F.interpolate(face1_tensor.unsqueeze(0), size=(G.img_resolution, G.img_resolution), mode='bilinear', align_corners=False)\n",
    "face1_tensor = face1_tensor.squeeze(0)\n",
    "\n",
    "face2_tensor = face2_tensor.squeeze()\n",
    "face2_tensor = face2_tensor.permute(2, 0, 1)\n",
    "face2_tensor = F.interpolate(face2_tensor.unsqueeze(0), size=(G.img_resolution, G.img_resolution), mode='bilinear', align_corners=False)\n",
    "face2_tensor = face2_tensor.squeeze(0)\n",
    "\n",
    "face1_tensor = face1_tensor.to(device)\n",
    "face2_tensor = face2_tensor.to(device)\n",
    "\n",
    "# Debugging: Print the shapes\n",
    "print(f\"face1_tensor shape: {face1_tensor.shape}\")\n",
    "print(f\"face2_tensor shape: {face2_tensor.shape}\")\n",
    "print(f\"Expected shape: ({G.img_channels}, {G.img_resolution}, {G.img_resolution})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n",
      "step    1/50: dist 0.60 loss 26969.62\n",
      "step    2/50: dist 0.61 loss 67702.83\n",
      "step    3/50: dist 0.58 loss 59981.11\n",
      "step    4/50: dist 0.50 loss 45369.52\n",
      "step    5/50: dist 0.50 loss 33338.46\n",
      "step    6/50: dist 0.47 loss 22501.75\n",
      "step    7/50: dist 0.42 loss 15647.18\n",
      "step    8/50: dist 0.43 loss 11920.53\n",
      "step    9/50: dist 0.40 loss 8755.54\n",
      "step   10/50: dist 0.40 loss 6729.27\n",
      "step   11/50: dist 0.44 loss 5830.00\n",
      "step   12/50: dist 0.34 loss 4896.45\n",
      "step   13/50: dist 0.35 loss 3967.25\n",
      "step   14/50: dist 0.33 loss 3462.77\n",
      "step   15/50: dist 0.31 loss 3050.70\n",
      "step   16/50: dist 0.32 loss 2418.59\n",
      "step   17/50: dist 0.32 loss 1878.26\n",
      "step   18/50: dist 0.30 loss 1683.52\n",
      "step   19/50: dist 0.29 loss 1724.79\n",
      "step   20/50: dist 0.29 loss 1878.25\n",
      "step   21/50: dist 0.30 loss 2115.12\n",
      "step   22/50: dist 0.29 loss 2312.22\n",
      "step   23/50: dist 0.29 loss 2301.37\n",
      "step   24/50: dist 0.28 loss 2038.61\n",
      "step   25/50: dist 0.28 loss 1599.96\n",
      "step   26/50: dist 0.28 loss 1102.09\n",
      "step   27/50: dist 0.28 loss 693.70\n",
      "step   28/50: dist 0.27 loss 479.04\n",
      "step   29/50: dist 0.27 loss 463.02\n",
      "step   30/50: dist 0.26 loss 610.36\n",
      "step   31/50: dist 0.26 loss 832.29\n",
      "step   32/50: dist 0.26 loss 981.20\n",
      "step   33/50: dist 0.26 loss 981.96\n",
      "step   34/50: dist 0.26 loss 860.30\n",
      "step   35/50: dist 0.26 loss 657.93\n",
      "step   36/50: dist 0.26 loss 423.16\n",
      "step   37/50: dist 0.25 loss 227.58\n",
      "step   38/50: dist 0.25 loss 122.92\n",
      "step   39/50: dist 0.25 loss 111.13\n",
      "step   40/50: dist 0.25 loss 171.88\n",
      "step   41/50: dist 0.25 loss 272.03\n",
      "step   42/50: dist 0.25 loss 351.37\n",
      "step   43/50: dist 0.25 loss 368.12\n",
      "step   44/50: dist 0.25 loss 331.64\n",
      "step   45/50: dist 0.24 loss 270.80\n",
      "step   46/50: dist 0.24 loss 208.56\n",
      "step   47/50: dist 0.24 loss 158.25\n",
      "step   48/50: dist 0.24 loss 124.00\n",
      "step   49/50: dist 0.24 loss 104.13\n",
      "step   50/50: dist 0.24 loss 94.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Project the image\n",
    "projected_w_steps1 = projector.project(\n",
    "    G,\n",
    "    target=face1_tensor,  # Your target image tensor\n",
    "    num_steps=50,  # Number of optimization steps\n",
    "    device=device,\n",
    "    verbose=True  # Print optimization progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n",
      "step    1/50: dist 0.62 loss 2908.40\n",
      "step    2/50: dist 0.54 loss 4715.89\n",
      "step    3/50: dist 0.59 loss 3453.03\n",
      "step    4/50: dist 0.55 loss 1272.85\n",
      "step    5/50: dist 0.53 loss 5440.22\n",
      "step    6/50: dist 0.51 loss 5022.19\n",
      "step    7/50: dist 0.48 loss 3673.22\n",
      "step    8/50: dist 0.47 loss 2854.46\n",
      "step    9/50: dist 0.47 loss 1501.33\n",
      "step   10/50: dist 0.47 loss 1166.68\n",
      "step   11/50: dist 0.44 loss 1931.36\n",
      "step   12/50: dist 0.43 loss 2124.79\n",
      "step   13/50: dist 0.45 loss 1565.36\n",
      "step   14/50: dist 0.42 loss 1173.43\n",
      "step   15/50: dist 0.45 loss 1135.63\n",
      "step   16/50: dist 0.45 loss 1009.88\n",
      "step   17/50: dist 0.43 loss 775.13\n",
      "step   18/50: dist 0.42 loss 739.83\n",
      "step   19/50: dist 0.41 loss 842.73\n",
      "step   20/50: dist 0.41 loss 787.93\n",
      "step   21/50: dist 0.40 loss 611.14\n",
      "step   22/50: dist 0.40 loss 532.31\n",
      "step   23/50: dist 0.40 loss 517.55\n",
      "step   24/50: dist 0.40 loss 437.93\n",
      "step   25/50: dist 0.39 loss 332.23\n",
      "step   26/50: dist 0.39 loss 296.44\n",
      "step   27/50: dist 0.38 loss 323.70\n",
      "step   28/50: dist 0.37 loss 338.76\n",
      "step   29/50: dist 0.37 loss 313.23\n",
      "step   30/50: dist 0.37 loss 286.37\n",
      "step   31/50: dist 0.37 loss 263.77\n",
      "step   32/50: dist 0.37 loss 205.73\n",
      "step   33/50: dist 0.36 loss 128.42\n",
      "step   34/50: dist 0.36 loss 94.04\n",
      "step   35/50: dist 0.36 loss 116.93\n",
      "step   36/50: dist 0.36 loss 142.61\n",
      "step   37/50: dist 0.35 loss 144.42\n",
      "step   38/50: dist 0.35 loss 146.78\n",
      "step   39/50: dist 0.35 loss 136.57\n",
      "step   40/50: dist 0.34 loss 89.47\n",
      "step   41/50: dist 0.34 loss 50.47\n",
      "step   42/50: dist 0.34 loss 45.64\n",
      "step   43/50: dist 0.34 loss 48.77\n",
      "step   44/50: dist 0.34 loss 47.21\n",
      "step   45/50: dist 0.34 loss 45.40\n",
      "step   46/50: dist 0.34 loss 43.00\n",
      "step   47/50: dist 0.34 loss 38.52\n",
      "step   48/50: dist 0.34 loss 33.27\n",
      "step   49/50: dist 0.34 loss 29.06\n",
      "step   50/50: dist 0.33 loss 26.69\n"
     ]
    }
   ],
   "source": [
    "projected_w_steps2 = projector.project(\n",
    "    G,\n",
    "    target=face2_tensor,  # Your target image tensor\n",
    "    num_steps=50,  # Number of optimization steps\n",
    "    device=device,\n",
    "    verbose=True  # Print optimization progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_w_steps1.shape\n",
    "projected_w_steps2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the projected_w_steps1 and projected_w_steps2 are exactly the same\n",
    "(projected_w_steps1 == projected_w_steps2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 7.65 GB, other allocations: 9.30 GB, max allowed: 18.13 GB). Tried to allocate 1.56 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      2\u001b[0m w1 \u001b[38;5;241m=\u001b[39m projected_w_steps1\n\u001b[0;32m----> 4\u001b[0m img1 \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_fp32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m img1 \u001b[38;5;241m=\u001b[39m (img1\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39muint8)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#show the image\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<string>:463\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, ws, **block_kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<string>:397\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, img, ws, force_fp32, fused_modconv, **layer_kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<string>:296\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, w, noise_mode, fused_modconv, gain)\u001b[0m\n",
      "File \u001b[0;32m~/Local Documents/github/facemorph/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:89\u001b[0m, in \u001b[0;36mbias_act\u001b[0;34m(x, b, dim, act, alpha, gain, clamp, impl)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impl \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _init():\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _bias_act_cuda(dim\u001b[38;5;241m=\u001b[39mdim, act\u001b[38;5;241m=\u001b[39mact, alpha\u001b[38;5;241m=\u001b[39malpha, gain\u001b[38;5;241m=\u001b[39mgain, clamp\u001b[38;5;241m=\u001b[39mclamp)\u001b[38;5;241m.\u001b[39mapply(x, b)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bias_act_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Local Documents/github/facemorph/stylegan2-ada-pytorch/torch_utils/misc.py:101\u001b[0m, in \u001b[0;36mprofiled_function.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Local Documents/github/facemorph/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:113\u001b[0m, in \u001b[0;36m_bias_act_ref\u001b[0;34m(x, b, dim, act, alpha, gain, clamp)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Evaluate activation function.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(alpha)\n\u001b[0;32m--> 113\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Scale by gain.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(gain)\n",
      "File \u001b[0;32m~/Local Documents/github/facemorph/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:26\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x, alpha, **_)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m misc\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     23\u001b[0m activation_funcs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:   dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         x,                                          def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,             cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,  has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m:     dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(x),                def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m),    cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlrelu\u001b[39m\u001b[38;5;124m'\u001b[39m:    dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, alpha, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:  \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m,   def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  def_gain\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m),    cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m:     dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39mtanh(x),                              def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,             cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m:  dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39msigmoid(x),                           def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,             cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melu\u001b[39m\u001b[38;5;124m'\u001b[39m:      dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39melu(x),                 def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,             cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselu\u001b[39m\u001b[38;5;124m'\u001b[39m:     dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mselu(x),                def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,             cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftplus\u001b[39m\u001b[38;5;124m'\u001b[39m: dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftplus(x),            def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,             cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswish\u001b[39m\u001b[38;5;124m'\u001b[39m:    dnnlib\u001b[38;5;241m.\u001b[39mEasyDict(func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_:         torch\u001b[38;5;241m.\u001b[39msigmoid(x) \u001b[38;5;241m*\u001b[39m x,                       def_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,    def_gain\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m),    cuda_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, has_2nd_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     33\u001b[0m }\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     37\u001b[0m _inited \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/facemorphing/lib/python3.8/site-packages/torch/nn/functional.py:1677\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1675\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu_(\u001b[38;5;28minput\u001b[39m, negative_slope)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1677\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 7.65 GB, other allocations: 9.30 GB, max allowed: 18.13 GB). Tried to allocate 1.56 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "w1 = projected_w_steps1\n",
    "\n",
    "img1 = G.synthesis(w1, noise_mode='const', force_fp32=True)\n",
    "\n",
    "img1 = (img1.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "\n",
    "#show the image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = projected_w_steps2\n",
    "img2 = G.synthesis(w2, noise_mode='const', force_fp32=True)\n",
    "img2 = (img2.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facemorphing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
